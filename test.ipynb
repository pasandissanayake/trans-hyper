{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5313ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from datahandles import preprocess_numeric\n",
    "from utils import Config\n",
    "\n",
    "from tabllm import load_dataset, load_and_preprocess_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84517692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       white_piece0_strength  white_piece0_file  white_piece0_rank  \\\n",
      "0                        0.0                1.0                8.0   \n",
      "1                        0.0                2.0                8.0   \n",
      "2                        0.0                4.0                8.0   \n",
      "3                        0.0                5.0                8.0   \n",
      "4                        0.0                6.0                8.0   \n",
      "...                      ...                ...                ...   \n",
      "44814                    7.0                6.0                1.0   \n",
      "44815                    7.0                0.0                0.0   \n",
      "44816                    7.0                1.0                0.0   \n",
      "44817                    7.0                2.0                0.0   \n",
      "44818                    7.0                4.0                0.0   \n",
      "\n",
      "       black_piece0_strength  black_piece0_file  black_piece0_rank  label  \n",
      "0                        0.0                0.0                8.0   True  \n",
      "1                        0.0                0.0                8.0   True  \n",
      "2                        0.0                0.0                8.0   True  \n",
      "3                        0.0                0.0                8.0   True  \n",
      "4                        0.0                0.0                8.0   True  \n",
      "...                      ...                ...                ...    ...  \n",
      "44814                    7.0                6.0                0.0   True  \n",
      "44815                    7.0                6.0                0.0  False  \n",
      "44816                    7.0                6.0                0.0  False  \n",
      "44817                    7.0                6.0                0.0  False  \n",
      "44818                    7.0                6.0                0.0  False  \n",
      "\n",
      "[44819 rows x 7 columns]\n",
      "Index(['white_piece0_strength', 'white_piece0_file', 'white_piece0_rank',\n",
      "       'black_piece0_strength', 'black_piece0_file', 'black_piece0_rank',\n",
      "       'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ds_name = 'jungle'\n",
    "ds_raw = load_dataset(dataset_name=ds_name, data_dir=Path(f'./tabllm/data/datasets/{ds_name}'))\n",
    "print(ds_raw)\n",
    "print(ds_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9191ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['white_piece0_rank', 'white_piece0_file', 'black_piece0_strength', 'black_piece0_rank', 'white_piece0_strength', 'black_piece0_file']\n"
     ]
    }
   ],
   "source": [
    "all_cols = ['white_piece0_strength', 'white_piece0_file', 'white_piece0_rank',\n",
    "       'black_piece0_strength', 'black_piece0_file', 'black_piece0_rank']\n",
    "categorical = []\n",
    "numerical = list(set(all_cols) - set(categorical) - set(['label']))\n",
    "\n",
    "print(categorical)\n",
    "print(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f2030f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fsspec.implementations.cached'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m ds_raw = load_and_preprocess_dataset(dataset_name=ds_name, data_dir=Path(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./tabllm/data/datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m))\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# print(ds_raw)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ds_txt = \u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtabllm/data/datasets_serialized/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mds_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m ds_txt = pd.DataFrame(ds_txt) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m      6\u001b[39m val_counts = ds_raw[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transhyper/lib/python3.13/site-packages/datasets/load.py:2138\u001b[39m, in \u001b[36mload_from_disk\u001b[39m\u001b[34m(dataset_path, keep_in_memory, storage_options)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transhyper/lib/python3.13/site-packages/fsspec/core.py:403\u001b[39m, in \u001b[36murl_to_fs\u001b[39m\u001b[34m(url, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/transhyper/lib/python3.13/site-packages/fsspec/core.py:333\u001b[39m, in \u001b[36m_un_chain\u001b[39m\u001b[34m(path, kwargs)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fsspec.implementations.cached'"
     ]
    }
   ],
   "source": [
    "ds_name = 'income'\n",
    "ds_raw = load_and_preprocess_dataset(dataset_name=ds_name, data_dir=Path(f'./tabllm/data/datasets/{ds_name}'))\n",
    "# print(ds_raw)\n",
    "ds_txt = load_from_disk(f\"tabllm/data/datasets_serialized/{ds_name}\")\n",
    "ds_txt = pd.DataFrame(ds_txt) # type: ignore\n",
    "val_counts = ds_raw['label'].value_counts()\n",
    "print(val_counts)\n",
    "print('Max const. predictor acc:', max(val_counts)/sum(val_counts) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a64513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age         workclass     education      marital_status  \\\n",
      "16465   39  Self-emp-not-inc          11th  Married-civ-spouse   \n",
      "5625    54  Self-emp-not-inc     Bachelors  Married-civ-spouse   \n",
      "30273   32           Private       HS-grad  Married-civ-spouse   \n",
      "3136    45  Self-emp-not-inc  Some-college       Never-married   \n",
      "4521    60           Private          10th  Married-civ-spouse   \n",
      "...    ...               ...           ...                 ...   \n",
      "32511   25         Local-gov     Bachelors       Never-married   \n",
      "5192    32           Private     Bachelors  Married-civ-spouse   \n",
      "12172   27           Private     Bachelors       Never-married   \n",
      "235     59         State-gov       HS-grad  Married-civ-spouse   \n",
      "29733   33           Private     Bachelors  Married-civ-spouse   \n",
      "\n",
      "              occupation   relationship                race     sex  \\\n",
      "16465   Transport-moving        Husband               White    Male   \n",
      "5625     Exec-managerial        Husband               White    Male   \n",
      "30273              Sales        Husband               White    Male   \n",
      "3136     Farming-fishing  Not-in-family               White    Male   \n",
      "4521   Handlers-cleaners        Husband               Black    Male   \n",
      "...                  ...            ...                 ...     ...   \n",
      "32511       Adm-clerical      Own-child               Black  Female   \n",
      "5192     Exec-managerial        Husband               White    Male   \n",
      "12172  Machine-op-inspct  Not-in-family  Asian-Pac-Islander    Male   \n",
      "235        Other-service        Husband               White    Male   \n",
      "29733       Adm-clerical        Husband               White    Male   \n",
      "\n",
      "       capital_gain  capital_loss  hours_per_week native_country  label  \n",
      "16465             0             0              40  United-States  False  \n",
      "5625              0             0              40  United-States   True  \n",
      "30273             0          1902              50  United-States   True  \n",
      "3136              0             0              50  United-States  False  \n",
      "4521              0             0              40  United-States  False  \n",
      "...             ...           ...             ...            ...    ...  \n",
      "32511             0             0              40  United-States  False  \n",
      "5192          15024             0              45  United-States   True  \n",
      "12172             0             0              40            NaN  False  \n",
      "235               0             0              40  United-States  False  \n",
      "29733             0          1902              45  United-States   True  \n",
      "\n",
      "[26048 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "ds_name = \"income\"\n",
    "# ds = load_from_disk(f\"tabllm/data/data_ser/{ds_name}\")\n",
    "ds = load_dataset(dataset_name=ds_name, data_dir=Path(f\"./tabllm/data/datasets/{ds_name}\"))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5ae0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = BertModel.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df75bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    # if \"classifier\" not in name: # Assuming the last layer is named \"classifier\"\n",
    "    #     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3603cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabLLMDataObject initialized with 3 training set(s), 1 validation set(s), and 1 test set(s).\n",
      "Maximum number of features across all datasets: 103\n",
      "Hyponet in_dim set to max number of features (=103)\n",
      "Balancing train split\n",
      "split: train, counts: [label\n",
      "True     133\n",
      "False    133\n",
      "Name: count, dtype: int64, label\n",
      "False    2576\n",
      "True     2576\n",
      "Name: count, dtype: int64, label\n",
      "True     5789\n",
      "False    5789\n",
      "Name: count, dtype: int64, label\n",
      "False    5158\n",
      "True     5158\n",
      "Name: count, dtype: int64]\n",
      "Balancing val split\n",
      "split: val, counts: [label\n",
      "True     72\n",
      "False    72\n",
      "Name: count, dtype: int64, label\n",
      "False    1093\n",
      "True     1093\n",
      "Name: count, dtype: int64, label\n",
      "False    2405\n",
      "True     2405\n",
      "Name: count, dtype: int64, label\n",
      "True     2020\n",
      "False    2020\n",
      "Name: count, dtype: int64]\n",
      "Balancing test split\n",
      "split: test, counts: [label\n",
      "True     95\n",
      "False    95\n",
      "Name: count, dtype: int64, label\n",
      "True     1620\n",
      "False    1620\n",
      "Name: count, dtype: int64, label\n",
      "True     3493\n",
      "False    3493\n",
      "Name: count, dtype: int64, label\n",
      "True     3057\n",
      "False    3057\n",
      "Name: count, dtype: int64]\n",
      "{'x': array([-0.73866755, -0.6625461 ,  0.02414692,  0.12788287, -0.704926  ,\n",
      "       -0.42828956,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ], dtype=float32), 'y': np.int64(1), 'text': 'Example: The Status of existing checking account is no checking account. The Duration in month is 12. The Credit history is critical account/ other credits existing (not at this bank). The Purpose is furniture/equipment. The Credit amount is 1402. The Savings account/bonds is 500 &lt;= ... &lt; 1000 DM. The Present employment since is 4&lt;=X&lt;7. The Installment rate in percentage of disposable income is 3. The Personal status and sex is female : divorced/separated/married. The Other debtors / guarantors is none. The Present residence since is 4. The Property is car or other, not in attribute 6. The Age in years is 37. The Other installment plans is none. The Housing is rent. The Number of existing credits at this bank is 1. The Job is skilled employee / official. The Number of people being liable to provide maintenance for is 1.0. The Telephone is yes, registered under the customers name. The foreign worker is yes.\\n\\nDoes this person receive a credit? Yes or no? Answer:\\n'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m tabllm_do\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_ds[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mtokenize(test_ds[\u001b[38;5;241m0\u001b[39m])))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import Config, ConfigObject\n",
    "from datahandles import TabLLMDataObject, CombinedTabLLMTextDataset\n",
    "import yaml\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "import os\n",
    "\n",
    "cfg = Config(\"./cfgs/t0.yaml\")\n",
    "tabllm_do = TabLLMDataObject(cfg, set_hyponet_in_dim=True)\n",
    "test_ds = tabllm_do.data['test']\n",
    "print(test_ds[0])\n",
    "\n",
    "print(len(tokenizer.tokenize(test_ds[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb20d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "if \"decoder\" not in \"66.decoder.manam\":\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04a8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507281250\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now().strftime(\"%y%m%d%H%M\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transhyper2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
